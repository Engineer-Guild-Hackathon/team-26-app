import { useState, useEffect, useRef, useCallback } from 'react'
import { useNavigate } from 'react-router-dom'
import TalkAnimation from '../components/TalkAnimation'
import { type MaterialFolder, type MaterialFile, firebaseMaterialsService } from 'src/services/firebaseMaterials'


// CSS for animations and styling
const styles = `
 @keyframes pulse {
   0% { opacity: 1; transform: scale(1); }
   50% { opacity: 0.5; transform: scale(0.9); }
   100% { opacity: 1; transform: scale(1); }
 }
 .no-scrollbar::-webkit-scrollbar {
   display: none;
 }
 .no-scrollbar {
   -ms-overflow-style: none;
   scrollbar-width: none;
 }
`
if (typeof document !== 'undefined') {
 const styleElement = document.createElement('style')
 styleElement.textContent = styles
 document.head.appendChild(styleElement)
}


// WebRTC Realtime AI Client
class WebRTCRealtimeClient {
 private pc: RTCPeerConnection | null = null
 private dataChannel: RTCDataChannel | null = null
 private mediaStream: MediaStream | null = null
 private onMessage: (message: any) => void
 // private onAudioResponse: (audioData: string) => void - ç¾åœ¨æœªä½¿ç”¨
 // private breakId: string - ç¾åœ¨æœªä½¿ç”¨
 private isSending: boolean = false // é€ä¿¡çŠ¶æ…‹ç®¡ç†
 private isResponseActive: boolean = false // ãƒ¬ã‚¹ãƒãƒ³ã‚¹çŠ¶æ…‹ç®¡ç†


 constructor(_breakId: string, onMessage: (message: any) => void, _onAudioResponse: (audioData: string) => void) {
   // this.breakId = breakId - ç¾åœ¨æœªä½¿ç”¨
   this.onMessage = onMessage
   // this.onAudioResponse = _onAudioResponse - ç¾åœ¨æœªä½¿ç”¨
 }


 async connect() {
   try {
     console.log('WebRTCæ¥ç¶šé–‹å§‹...')
    
     // 1. ephemeral keyã‚’å–å¾—
     const apiUrl = import.meta.env.VITE_API_URL || 'http://localhost:3001'
     const sessionResp = await fetch(`${apiUrl}/session/create`, {
       method: 'POST',
       headers: { 'Content-Type': 'application/json' }
     })
    
     if (!sessionResp.ok) {
       throw new Error('ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ')
     }
    
     const sessionData = await sessionResp.json()
     console.log('Session created:', sessionData)


     // 2. RTCPeerConnectionä½œæˆ
     this.pc = new RTCPeerConnection()


     // 3. ãƒã‚¤ã‚¯éŸ³å£°ã‚’å–å¾—
     this.mediaStream = await navigator.mediaDevices.getUserMedia({
       audio: {
         echoCancellation: true,
         noiseSuppression: true,
         autoGainControl: true,
         sampleRate: 24000
       }
     })
    
     this.mediaStream.getTracks().forEach((track) => {
       this.pc!.addTrack(track, this.mediaStream!)
     })


     // 4. ãƒ‡ãƒ¼ã‚¿ãƒãƒ£ãƒ³ãƒãƒ«ä½œæˆ
     this.dataChannel = this.pc.createDataChannel("oai-events")
     this.setupDataChannelEvents()


     // 5. WebRTCã‚¤ãƒ™ãƒ³ãƒˆè¨­å®š
     this.pc.addEventListener("track", (event) => {
       console.log("Received track:", event.track.kind)
       if (event.track.kind === "audio") {
         const audio = new Audio()
         audio.srcObject = event.streams[0]
         audio.play()
       }
     })


     // 6. Offerä½œæˆãƒ»é€ä¿¡
     const offer = await this.pc.createOffer()
     await this.pc.setLocalDescription(offer)


     const sdpResp = await fetch(`https://api.openai.com/v1/realtime?model=gpt-realtime`, {
       method: "POST",
       headers: {
         "Authorization": `Bearer ${sessionData.client_secret.value}`,
         "Content-Type": "application/sdp",
       },
       body: offer.sdp,
     })


     if (!sdpResp.ok) {
       throw new Error("SDP answerå–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
     }


     const answerSdp = await sdpResp.text()
     await this.pc.setRemoteDescription({ type: "answer", sdp: answerSdp })


     this.onMessage({
       type: 'connected',
       message: 'WebRTCæ¥ç¶šå®Œäº†ï¼ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ä¼šè©±ãŒé–‹å§‹ã•ã‚Œã¾ã—ãŸğŸ¤'
     })


   } catch (error) {
     console.error('WebRTC connection error:', error)
     this.onMessage({ type: 'error', message: `æ¥ç¶šã‚¨ãƒ©ãƒ¼: ${error instanceof Error ? error.message : String(error)}` })
   }
 }


 private setupDataChannelEvents() {
   if (!this.dataChannel) return


   this.dataChannel.addEventListener("open", () => {
     console.log("Data channel opened")
    
     // ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®šï¼ˆç”»åƒå¯¾å¿œï¼‰
     const sessionUpdate = {
       type: "session.update",
       session: {
         modalities: ["text", "audio"],
         turn_detection: {
           type: "server_vad",
           threshold: 0.5,
           prefix_padding_ms: 300,
           silence_duration_ms: 500,
         },
         voice: "alloy",
         input_audio_format: "pcm16",
         output_audio_format: "pcm16",
         instructions: `ã‚ãªãŸã¯ä¸€ç·’ã«å‹‰å¼·ã—ã¦ã„ã‚‹è¦ªã—ã„å‹é”ã§ã™ã€‚Study with meã§åŒã˜åˆ†é‡ã‚’å‹‰å¼·ã—ã¦ã„ã‚‹ä»²é–“ã¨ã—ã¦ã€ã‚¿ãƒ¡å£ã§æ°—è»½ã«è©±ã—ã‹ã‘ã¦ãã ã•ã„ã€‚


ä¼šè©±ã®ç‰¹å¾´ï¼š
- ã‚¿ãƒ¡å£ã§è¦ªã—ã¿ã‚„ã™ãï¼ˆã€Œã€œã ã‚ˆã€ã€Œã€œã˜ã‚ƒã‚“ã€ãªã©ï¼‰
- ãŸã¾ã«è»½ãã„ã˜ã£ãŸã‚Šå†—è«‡ã‚’è¨€ã†å‹é”é–¢ä¿‚
- åŒã˜åˆ†é‡ã‚’ä¸€ç·’ã«å‹‰å¼·ã—ã¦ã„ã‚‹ä»²é–“æ„Ÿã‚’å‡ºã™
- çŸ­ã‚ã®è¿”ç­”ï¼ˆ1-2æ–‡ç¨‹åº¦ï¼‰
- çµµæ–‡å­—ã‚’é©åº¦ã«ä½¿ç”¨


æ•™æã«ã¤ã„ã¦ãƒ•ãƒ©ãƒ³ã‚¯ã«è©±ã—ã€å­¦ç¿’è€…ã‚’åŠ±ã¾ã—ã¦ãã ã•ã„ã€‚`,
       },
     }
     this.dataChannel!.send(JSON.stringify(sessionUpdate))


     this.onMessage({ type: 'connected' })
   })


   this.dataChannel.addEventListener("message", (event) => {
     const data = JSON.parse(event.data)
     // é‡è¦ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã¿ãƒ­ã‚°å‡ºåŠ›
     if (data.type.includes('error') || data.type.includes('done') || data.type.includes('created')) {
       console.log("Data channel message:", data)
     }
    
     this.handleRealtimeMessage(data)
   })


   this.dataChannel.addEventListener("close", () => {
     console.warn("Data channel closed")
   })


   this.dataChannel.addEventListener("error", (error) => {
     console.error("Data channel error:", error)
     // ã‚¨ãƒ©ãƒ¼æ™‚ã¯çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
     this.isSending = false
     this.isResponseActive = false
     this.onMessage({
       type: 'error',
       message: 'DataChannelæ¥ç¶šã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚å†æ¥ç¶šã—ã¦ãã ã•ã„ã€‚'
     })
   })
 }


 private handleRealtimeMessage(data: any) {
   switch (data.type) {
     case "response.audio.delta":
       if (data.delta) {
         console.log("Audio delta received, length:", data.delta.length)
         this.playAudioDelta(data.delta)
       }
       break


     case "response.audio.done":
       console.log("Audio response done")
       this.onMessage({ type: 'ai_audio_done', message: 'ğŸ”Š éŸ³å£°å¿œç­”å®Œäº†' })
       break


     case "response.created":
       console.log("Response started")
       this.isResponseActive = true // ãƒ¬ã‚¹ãƒãƒ³ã‚¹é–‹å§‹
       this.onMessage({ type: 'ai_response_started', message: 'ğŸ¤– AIå¿œç­”é–‹å§‹...' })
       break


     case "conversation.item.input_audio_transcription.completed":
       console.log("User transcription:", data.transcript)
       this.onMessage({
         type: 'user_transcription',
         message: `ğŸ¤ ã‚ãªãŸ: ${data.transcript}`,
         transcript: data.transcript
       })
       break


     case "response.text.delta":
       if (data.delta) {
         this.onMessage({
           type: 'ai_text_delta',
           content: data.delta
         })
       }
       break


     case "response.text.done":
       console.log("Text response done:", data.text)
       this.onMessage({
         type: 'ai_text_done',
         message: `ğŸ¤– ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼: ${data.text}`
       })
       break


     case "response.done":
       console.log("Response completed")
       this.isResponseActive = false // ãƒ¬ã‚¹ãƒãƒ³ã‚¹å®Œäº†
       this.isSending = false // é€ä¿¡çŠ¶æ…‹ã‚‚ãƒªã‚»ãƒƒãƒˆ
      
       if (data.response && data.response.status === 'failed') {
         console.error("ğŸš¨ Response failed:", data.response.status_details)
         this.onMessage({
           type: 'error',
           message: `âŒ AIå¿œç­”ã‚¨ãƒ©ãƒ¼: ${data.response.status_details?.error?.message || 'Unknown error'}`
         })
       } else {
         this.onMessage({ type: 'ai_response_done', message: 'âœ… å¿œç­”å®Œäº†' })
       }
       break


     case "error":
       console.error("OpenAI API error:", data.error)
       this.onMessage({ type: 'error', message: `âš ï¸ ã‚¨ãƒ©ãƒ¼: ${data.error.message}` })
       break
   }
 }


 private playAudioDelta(delta: string) {
   try {
     const audioData = atob(delta)
     const audioArray = new Uint8Array(audioData.length)
     for (let i = 0; i < audioData.length; i++) {
       audioArray[i] = audioData.charCodeAt(i)
     }
     this.playAudio(audioArray.buffer)
   } catch (error) {
     console.error('Audio playback error:', error)
   }
 }


 private playAudio(audioBuffer: ArrayBuffer) {
   const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)()
   audioContext.decodeAudioData(audioBuffer, (decodedData) => {
     const source = audioContext.createBufferSource()
     source.buffer = decodedData
     source.connect(audioContext.destination)
     source.start()
   }).catch(console.error)
 }


 // ç”»åƒåœ§ç¸®é–¢æ•°ï¼ˆBlobç‰ˆï¼‰
 private async compressImageBlob(blob: Blob, maxSizeKB: number): Promise<string> {
   return new Promise((resolve, reject) => {
       const img = new Image()
       img.onload = () => {
         const canvas = document.createElement('canvas')
         const ctx = canvas.getContext('2d')
         if (!ctx) {
         reject(new Error('Canvas context not available'))
           return
         }
        
       // é©åº¦ã«ç¸®å°ï¼ˆmaxSizeKBã«å¿œã˜ã¦ã‚µã‚¤ã‚ºèª¿æ•´ï¼‰
       const maxDimension = maxSizeKB > 80 ? 600 : 400
         let { width, height } = img
        
         if (width > height) {
           if (width > maxDimension) {
             height = (height * maxDimension) / width
             width = maxDimension
           }
         } else {
           if (height > maxDimension) {
             width = (width * maxDimension) / height
             height = maxDimension
           }
         }
        
         canvas.width = Math.round(width)
         canvas.height = Math.round(height)
        
       // é«˜å“è³ªãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
         ctx.imageSmoothingEnabled = true
         ctx.imageSmoothingQuality = 'high'
         ctx.drawImage(img, 0, 0, canvas.width, canvas.height)
        
       // å“è³ªã‚’æ®µéšçš„ã«ä¸‹ã’ã¦èª¿æ•´
       let quality = 0.85
         let compressed = canvas.toDataURL('image/jpeg', quality)
         let compressedSizeKB = (compressed.length * 0.75) / 1024
        
       while (compressedSizeKB > maxSizeKB && quality > 0.5) {
           quality -= 0.05
           compressed = canvas.toDataURL('image/jpeg', quality)
           compressedSizeKB = (compressed.length * 0.75) / 1024
         }
        
         resolve(compressed)
       }
      
     img.onerror = () => reject(new Error('Image load failed'))
     img.src = URL.createObjectURL(blob)
   })
 }


 // æ•™æé€ä¿¡æ©Ÿèƒ½
 async sendMaterial(material: MaterialFile, content?: string) {
   if (!this.dataChannel || this.dataChannel.readyState !== 'open') {
     console.error('Data channel not open. State:', this.dataChannel?.readyState)
     return
   }


   if (this.isSending) {
     console.warn('æ—¢ã«é€ä¿¡ä¸­ã§ã™ã€‚é‡è¤‡é€ä¿¡ã‚’é˜²æ­¢ã—ã¾ã™ã€‚')
     return
   }


   if (this.isResponseActive) {
     console.warn('AIå¿œç­”ä¸­ã§ã™ã€‚å¿œç­”å®Œäº†å¾Œã«å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚')
     return
   }


   this.isSending = true
   console.log('ğŸ“š æ•™æé€ä¿¡é–‹å§‹:', material.name)


   try {
     if (material.type === 'text' && content) {
       // ãƒ†ã‚­ã‚¹ãƒˆæ•™æã®å ´åˆ
   const textMessage = {
     type: "conversation.item.create",
     item: {
       type: "message",
       role: "user",
       content: [
         {
           type: "input_text",
               text: `ã€Œ${material.name}ã€ã«ã¤ã„ã¦è©±ãã†ï¼\n\nã€å†…å®¹ã€‘\n${content}`
             }
           ]
         }
       }
       this.dataChannel.send(JSON.stringify(textMessage))
      
     } else if (material.type === 'image' && material.downloadURL) {
       // ç”»åƒæ•™æã®å ´åˆï¼šãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒã®ä¸¡æ–¹ã‚’é€ä¿¡
       const textMessage = {
     type: "conversation.item.create",
     item: {
       type: "message",
       role: "user",
       content: [
         {
               type: "input_text",
               text: `ã€Œ${material.name}ã€ã¨ã„ã†ç”»åƒã«ã¤ã„ã¦è©±ãã†ï¼`
             }
           ]
         }
       }
       this.dataChannel.send(JSON.stringify(textMessage))
      
       // ç”»åƒã‚’base64ã«å¤‰æ›ã—ã¦é€ä¿¡
       setTimeout(async () => {
         try {
           console.log('ğŸ–¼ï¸ ç”»åƒã‚’base64ã«å¤‰æ›ä¸­:', material.downloadURL)
           const response = await fetch(material.downloadURL)
           const blob = await response.blob()
          
           // ç”»åƒã‚’åœ§ç¸®ã—ã¦ã‹ã‚‰Base64å¤‰æ›
           const compressedBase64 = await this.compressImageBlob(blob, 100) // 100KBåˆ¶é™
           console.log('âœ… åœ§ç¸®æ¸ˆã¿Base64å¤‰æ›å®Œäº†:', compressedBase64.substring(0, 100) + '...')
           console.log('ğŸ“Š åœ§ç¸®å¾Œã‚µã‚¤ã‚º:', Math.round((compressedBase64.length * 0.75) / 1024), 'KB')
          
           const imageMessage = {
     type: "conversation.item.create",
     item: {
       type: "message",
       role: "user",
       content: [
         {
           type: "input_image",
                   image_url: compressedBase64
                 }
               ]
             }
           }
          
           // ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚µã‚¤ã‚ºã‚’ãƒã‚§ãƒƒã‚¯
           const messageStr = JSON.stringify(imageMessage)
           const messageSizeKB = (messageStr.length * 0.75) / 1024
           console.log('ğŸ“¦ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚µã‚¤ã‚º:', messageSizeKB.toFixed(2), 'KB')
          
           if (messageSizeKB > 150) {
             console.warn('âš ï¸ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå¤§ãã™ãã¾ã™:', messageSizeKB.toFixed(2), 'KB')
             return
           }
          
           this.dataChannel!.send(messageStr)
          
     } catch (error) {
           console.error('âŒ ç”»åƒå‡¦ç†ã‚¨ãƒ©ãƒ¼:', error)
     }
       }, 100)
   }


   setTimeout(() => {
       const responseRequest = {
         type: 'response.create',
         response: {
           modalities: ['text', 'audio']
         }
       }
       this.dataChannel!.send(JSON.stringify(responseRequest))
       this.isSending = false
   }, 200)


   } catch (error) {
     console.error('æ•™æé€ä¿¡ã‚¨ãƒ©ãƒ¼:', error)
     this.isSending = false
   }
 }


 disconnect() {
   // çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
   this.isSending = false
   this.isResponseActive = false
  
   if (this.dataChannel) {
     this.dataChannel.close()
     this.dataChannel = null
   }
   if (this.pc) {
     this.pc.close()
     this.pc = null
   }
   if (this.mediaStream) {
     this.mediaStream.getTracks().forEach(track => track.stop())
     this.mediaStream = null
   }
 }
}


export default function Break() {
 const navigate = useNavigate()
 const [breakElapsedTime, setBreakElapsedTime] = useState(0)
 const [partialText, setPartialText] = useState('')
 const videoRef = useRef<HTMLVideoElement>(null)
 const [stream, setStream] = useState<MediaStream | null>(null)
  // WebRTC Realtime AIé–¢é€£
 const [aiClient, setAiClient] = useState<WebRTCRealtimeClient | null>(null)
 const [isAiConnected, setIsAiConnected] = useState(false)
 const [isConnecting, setIsConnecting] = useState(false)
 const [isAISpeaking, setIsAISpeaking] = useState(false)
 const [conversationLog, setConversationLog] = useState<{role: 'user' | 'ai', text: string}[]>([])
 const conversationEndRef = useRef<HTMLDivElement>(null);


 // æ•™æé¸æŠé–¢é€£ã®çŠ¶æ…‹
 const [allFolders, setAllFolders] = useState<MaterialFolder[]>([])
 const [currentFolder, setCurrentFolder] = useState<MaterialFolder | null>(null)
 const [files, setFiles] = useState<MaterialFile[]>([])
 const [selectedMaterial, setSelectedMaterial] = useState<MaterialFile | null>(null)
 const [breadcrumbs, setBreadcrumbs] = useState<MaterialFolder[]>([])
 const [_textContent, setTextContent] = useState<string | null>(null)
 const [_isContentLoading, setIsContentLoading] = useState(false)
  const [currentItemIndex, setCurrentItemIndex] = useState(0)
 const [currentItems, setCurrentItems] = useState<(MaterialFolder | MaterialFile)[]>([])
 const interactionPanelRef = useRef<HTMLDivElement>(null);
 const scrollContainerRef = useRef<HTMLDivElement>(null);
 const itemRefs = useRef<(HTMLDivElement | null)[]>([]);




 const handleAiMessage = useCallback((data: any) => {
   switch (data.type) {
     case 'connected': setIsAiConnected(true); setIsConnecting(false); break;
     case 'disconnected': setIsAiConnected(false); setIsConnecting(false); setIsAISpeaking(false); break;
     case 'response.created': setIsAISpeaking(true); setPartialText(''); break;
     case 'response.done': setIsAISpeaking(false); break;
     case "conversation.item.input_audio_transcription.completed":
       setConversationLog(prev => [...prev, { role: 'user', text: data.transcript }]);
       break;
     case "response.text.delta": setPartialText(prev => prev + data.delta); break;
     case "response.text.done":
       setConversationLog(prev => [...prev, { role: 'ai', text: data.text }]);
       setPartialText('');
       break;
     case "error":
       alert(`AIã‚¨ãƒ©ãƒ¼: ${data.error?.message || 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼'}`);
       setIsConnecting(false);
       setIsAiConnected(false);
       break;
   }
 }, []);


 const fetchAllFolders = useCallback(async () => {
   try {
     const rootFolders = await firebaseMaterialsService.getFolders();
     let allFoldersData: MaterialFolder[] = [...rootFolders];
     for (const folder of rootFolders) {
       const childFolders = await loadChildFolders(folder.id, allFoldersData);
       allFoldersData.push(...childFolders);
     }
     setAllFolders(allFoldersData);
   } catch (error) { console.error('ãƒ•ã‚©ãƒ«ãƒ€å–å¾—ã‚¨ãƒ©ãƒ¼:', error); }
 }, []);


 const loadChildFolders = async (parentId: string, currentFolders: MaterialFolder[]): Promise<MaterialFolder[]> => {
   try {
     const childFolders = await firebaseMaterialsService.getChildFolders(parentId)
     let allChildren: MaterialFolder[] = [...childFolders]
     for (const child of childFolders) {
       const grandChildren = await loadChildFolders(child.id, [...currentFolders, ...allChildren])
       allChildren = [...allChildren, ...grandChildren]
     }
     return allChildren
   } catch (error) {
     console.error(`å­ãƒ•ã‚©ãƒ«ãƒ€å–å¾—ã‚¨ãƒ©ãƒ¼ (parentId: ${parentId}):`, error)
     return []
   }
 };


 const fetchFiles = useCallback(async (folderId: string | null) => {
   try {
     const filesData = folderId ? await firebaseMaterialsService.getFiles(folderId) : [];
     setFiles(filesData);
   } catch (error) { console.error('ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼:', error); setFiles([]); }
 }, []);
  const generateBreadcrumbs = useCallback((folder: MaterialFolder | null) => {
   if (!folder) { setBreadcrumbs([]); return; }
   const newBreadcrumbs: MaterialFolder[] = [];
   let currentItem: MaterialFolder | undefined = folder;
   while (currentItem) {
     newBreadcrumbs.unshift(currentItem);
     currentItem = allFolders.find(f => f.id === currentItem?.parentId);
   }
   setBreadcrumbs(newBreadcrumbs);
 }, [allFolders]);


 const handleFolderClick = useCallback((folder: MaterialFolder) => {
   setCurrentFolder(folder);
   fetchFiles(folder.id);
   generateBreadcrumbs(folder);
 }, [allFolders, fetchFiles, generateBreadcrumbs]);


 const handleNavigateToRoot = useCallback(() => {
   setCurrentFolder(null);
   fetchFiles(null);
   setBreadcrumbs([]);
 }, [fetchFiles]);


 useEffect(() => {
   fetchAllFolders();
   const autoConnect = localStorage.getItem('autoConnectWebRTC');
   if (autoConnect === 'true') {
     localStorage.removeItem('autoConnectWebRTC');
     setTimeout(() => startConnection(), 1000);
   }
 }, [fetchAllFolders]);


 useEffect(() => {
   if (allFolders.length > 0 && !currentFolder) {
     fetchFiles(null)
   }
 }, [allFolders, currentFolder, fetchFiles]);


 const startConnection = useCallback(async () => {
   if (isConnecting || isAiConnected) return;
   setIsConnecting(true);
   const client = new WebRTCRealtimeClient('break_session', handleAiMessage, () => {});
   setAiClient(client);
   try {
     await client.connect();
   } catch (error) {
     console.error('Connection failed:', error);
     setIsConnecting(false);
   }
 }, [isConnecting, isAiConnected, handleAiMessage]);


 const sendMaterialToAI = useCallback(async () => {
   if (!selectedMaterial || !aiClient || !isAiConnected) return;
  
   let materialContent = ''
   if (selectedMaterial.type === 'text') {
       try {
           const content = await firebaseMaterialsService.getTextContent(selectedMaterial.id);
           materialContent = content;
       } catch (e) {
           console.error("Failed to fetch text content for AI");
       }
   }


   await aiClient.sendMaterial(selectedMaterial, materialContent);
 }, [selectedMaterial, aiClient, isAiConnected]);


 const handleKeyDown = useCallback((e: KeyboardEvent) => {
   if (e.target instanceof HTMLInputElement || e.target instanceof HTMLTextAreaElement) return;
   switch (e.key) {
     case 'ArrowRight': e.preventDefault(); if (currentItems.length > 0) setCurrentItemIndex(i => (i + 1) % currentItems.length); break;
     case 'ArrowLeft': e.preventDefault(); if (currentItems.length > 0) setCurrentItemIndex(i => (i - 1 + currentItems.length) % currentItems.length); break;
     case 'ArrowUp': {
       e.preventDefault();
       const parent = currentFolder ? allFolders.find(f => f.id === currentFolder.parentId) : null;
       if (parent) handleFolderClick(parent);
       else if (currentFolder) handleNavigateToRoot();
       break;
     }
     case 'ArrowDown': {
       e.preventDefault();
       const item = currentItems[currentItemIndex];
       if (item && 'parentId' in item) handleFolderClick(item as MaterialFolder);
       break;
     }
   }
 }, [currentItemIndex, currentItems, currentFolder, allFolders, handleFolderClick, handleNavigateToRoot]);


 useEffect(() => {
   const newChildFolders = allFolders.filter(folder => folder.parentId === (currentFolder?.id || null));
   const items = [...newChildFolders, ...files];
   setCurrentItems(items);
   setCurrentItemIndex(0);
   itemRefs.current = itemRefs.current.slice(0, items.length);
 }, [currentFolder, files, allFolders]);
  useEffect(() => {
   const item = currentItems[currentItemIndex];
   if (item && 'type' in item) {
       setSelectedMaterial(item as MaterialFile);
       // ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯å†…å®¹ã‚’å–å¾—
       if ((item as MaterialFile).type === 'text') {
         setIsContentLoading(true);
         firebaseMaterialsService.getTextContent((item as MaterialFile).id)
           .then(content => {
             setTextContent(content);
             setIsContentLoading(false);
           })
           .catch(error => {
             console.error('ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹å–å¾—ã‚¨ãƒ©ãƒ¼:', error);
             setTextContent(null);
             setIsContentLoading(false);
           });
       } else {
         setTextContent(null);
       }
       } else {
       setSelectedMaterial(null);
       setTextContent(null);
   }
 }, [currentItemIndex, currentItems]);
  useEffect(() => {
   const container = scrollContainerRef.current;
   const item = itemRefs.current[currentItemIndex];
   if (container && item) {
       const scrollLeft = item.offsetLeft - (container.offsetWidth / 2) + (item.offsetWidth / 2);
       container.scrollTo({ left: scrollLeft, behavior: 'smooth' });
   }
 }, [currentItemIndex]);


 useEffect(() => {
   conversationEndRef.current?.scrollIntoView({ behavior: 'smooth' });
 }, [conversationLog, partialText]);
  useEffect(() => {
   window.addEventListener('keydown', handleKeyDown);
   return () => window.removeEventListener('keydown', handleKeyDown);
 }, [handleKeyDown]);


 useEffect(() => {
   const startCamera = async () => {
     try {
       const mediaStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false })
       setStream(mediaStream)
       if (videoRef.current) videoRef.current.srcObject = mediaStream
     } catch (error) { console.error('ã‚«ãƒ¡ãƒ©ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼:', error) }
   }
   startCamera();
   return () => stream?.getTracks().forEach(track => track.stop());
 }, []);


 useEffect(() => {
   const timer = setInterval(() => setBreakElapsedTime(prev => prev + 1), 1000);
   return () => clearInterval(timer);
 }, []);


 const formatTime = (seconds: number) => {
   const mins = Math.floor(seconds / 60);
   const secs = seconds % 60;
   return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
 };


 const parentFolder = currentFolder ? allFolders.find(f => f.id === currentFolder.parentId) : null;
 const selectedItem = currentItems.length > 0 ? currentItems[currentItemIndex] : null;
 const isSelectedItemFolder = selectedItem && 'parentId' in selectedItem;


 return (
   <div style={{ width: '100vw', height: '100vh', display: 'flex', background: 'linear-gradient(135deg, #667eea 0%, #764ba2 100%)' }}>
     {/* Left Panel */}
     <div style={{ width: '300px', padding: '20px', display: 'flex', flexDirection: 'column', gap: '20px' }}>
       <div style={{ background: 'rgba(255, 255, 255, 0.15)', borderRadius: '16px', padding: '16px', border: '1px solid rgba(255, 255, 255, 0.2)' }}>
         <h3 style={{ margin: '0 0 12px 0', color: 'white', fontSize: '16px', textAlign: 'center' }}>Webã‚«ãƒ¡ãƒ©</h3>
         <div style={{ width: '100%', height: '150px', background: '#000', borderRadius: '12px', overflow: 'hidden' }}>
           <video ref={videoRef} autoPlay muted style={{ width: '100%', height: '100%', objectFit: 'cover' }} />
             </div>
             </div>
       <div style={{ background: 'rgba(255, 255, 255, 0.15)', borderRadius: '16px', padding: '20px', border: '1px solid rgba(255, 255, 255, 0.2)', textAlign: 'center' }}>
         <h3 style={{ margin: '0 0 8px 0', color: 'white', fontSize: '16px' }}>ä¼‘æ†©æ™‚é–“</h3>
         <div style={{ fontSize: '24px', fontWeight: 'bold', color: 'white', fontFamily: 'monospace' }}>{formatTime(breakElapsedTime)}</div>
           </div>
       <div ref={interactionPanelRef} style={{ flex: 1, background: 'rgba(255, 255, 255, 0.15)', borderRadius: '16px', padding: '16px', display: 'flex', flexDirection: 'column', overflow: 'hidden' }}>
         <h3 style={{ margin: '0 0 8px 0', color: 'white', fontSize: '16px', flexShrink: 0 }}>æ•™æã§è©±ã™</h3>
         <div style={{ marginBottom: '8px', fontSize: '12px', color: 'white', wordBreak: 'break-all', flexShrink: 0 }}>ğŸ“ {breadcrumbs.map(f => f.name).join(' / ') || 'ãƒ«ãƒ¼ãƒˆ'}</div>
         <div onClick={() => parentFolder ? handleFolderClick(parentFolder) : (currentFolder && handleNavigateToRoot())} style={{ textAlign: 'center', padding: '4px 0', fontSize: '12px', color: 'rgba(255, 255, 255, 0.8)', opacity: currentFolder ? 1 : 0.4, cursor: currentFolder ? 'pointer' : 'default', borderBottom: '1px solid rgba(255, 255, 255, 0.1)', marginBottom: '5px' }}>
           <span>â†‘ {parentFolder ? parentFolder.name : (currentFolder ? 'ãƒ«ãƒ¼ãƒˆã«æˆ»ã‚‹' : '')}</span>
         </div>
         <div ref={scrollContainerRef} className="no-scrollbar" style={{ display: 'flex', alignItems: 'center', overflowX: 'auto', padding: '10px 0' }}>
           {currentItems.length > 0 ? (
             <div style={{ display: 'flex', padding: `0 calc(50% - 50px)` }}>
               {currentItems.map((item, index) => (
                 <div ref={(el) => { itemRefs.current[index] = el; }} key={item.id} onClick={() => setCurrentItemIndex(index)} style={{ padding: '10px', background: index === currentItemIndex ? 'rgba(59, 130, 246, 0.4)' : 'rgba(255, 255, 255, 0.05)', border: `2px solid ${index === currentItemIndex ? 'rgba(59, 130, 246, 0.7)' : 'transparent'}`, borderRadius: '12px', margin: '0 5px', transition: 'all 0.3s ease', transform: index === currentItemIndex ? 'scale(1.08)' : 'scale(0.95)', opacity: index === currentItemIndex ? 1 : 0.7, display: 'flex', flexDirection: 'column', alignItems: 'center', justifyContent: 'center', gap: '8px', flexShrink: 0, width: '90px', height: '90px', cursor: 'pointer' }}>
                   <span style={{ fontSize: '32px' }}>{'parentId' in item ? 'ğŸ“' : (item.type === 'text' ? 'ğŸ“„' : 'ğŸ–¼ï¸')}</span>
                   <span style={{ color: 'white', fontWeight: '500', fontSize: '12px', textAlign: 'center', width: '100%', overflow: 'hidden', textOverflow: 'ellipsis', whiteSpace: 'nowrap' }}>{item.name}</span>
         </div>
               ))}
       </div>
           ) : <div style={{ textAlign: 'center', color: 'rgba(255, 255, 255, 0.7)', width: '100%' }}><p>ç©ºã®ãƒ•ã‚©ãƒ«ãƒ€</p></div>}
         </div>
         <div onClick={() => isSelectedItemFolder && handleFolderClick(selectedItem as MaterialFolder)} style={{ textAlign: 'center', padding: '4px 0', fontSize: '12px', color: 'rgba(255, 255, 255, 0.8)', height: '20px', opacity: isSelectedItemFolder ? 1 : 0.4, cursor: isSelectedItemFolder ? 'pointer' : 'default', borderTop: '1px solid rgba(255, 255, 255, 0.1)', marginTop: '5px' }}>
           {isSelectedItemFolder && selectedItem ? <span>â†“ {selectedItem.name} ã‚’é–‹ã</span> : <span></span>}
         </div>
         <button onClick={sendMaterialToAI} disabled={!isAiConnected || !selectedMaterial} style={{ width: '100%', padding: '10px', background: isAiConnected && selectedMaterial ? 'rgba(16, 185, 129, 0.8)' : 'rgba(107, 114, 128, 0.5)', color: 'white', border: 'none', borderRadius: '12px', cursor: isAiConnected && selectedMaterial ? 'pointer' : 'not-allowed', fontSize: '14px', fontWeight: '600', marginTop: '10px' }}>AIã«é€ä¿¡</button>
           </div>
       </div>


     {/* Right Panel */}
     <div style={{ flex: 1, position: 'relative', display: 'flex' }}>
       <div style={{ flex: 1, position: 'relative' }}>
         <TalkAnimation selectedMaterial={null} />
       </div>
       <div style={{ flex: 1, display: 'flex', alignItems: 'center', justifyContent: 'center', padding: '20px' }}>
         <div style={{ width: '90%', height: '90%', background: 'rgba(0, 0, 0, 0.3)', backdropFilter: 'blur(5px)', borderRadius: '16px', padding: '20px', overflow: 'auto', color: 'white', display: 'flex', flexDirection: 'column', gap: '15px' }}>
           {conversationLog.map((entry, index) => (
             <div key={index} style={{ display: 'flex', gap: '10px', alignItems: 'flex-start', justifyContent: entry.role === 'user' ? 'flex-end' : 'flex-start' }}>
               <div style={{ order: entry.role === 'user' ? 2 : 1, fontSize: '24px' }}>{entry.role === 'user' ? 'ğŸ‘¤' : 'ğŸ¤–'}</div>
               <p style={{ order: entry.role === 'user' ? 1 : 2, background: entry.role === 'user' ? 'rgba(59, 130, 246, 0.5)' : 'rgba(255, 255, 255, 0.2)', padding: '10px 15px', borderRadius: '12px', margin: 0, maxWidth: '80%' }}>{entry.text}</p>
             </div>
           ))}
       {isAISpeaking && (
             <div style={{ display: 'flex', gap: '10px', alignItems: 'flex-start' }}>
               <div style={{ fontSize: '24px' }}>ğŸ¤–</div>
               <p style={{ background: 'rgba(255, 255, 255, 0.2)', padding: '10px 15px', borderRadius: '12px', margin: 0, maxWidth: '80%', opacity: 0.8 }}>
                 {partialText || <span style={{animation: 'pulse 1.5s infinite'}}>...</span>}
               </p>
         </div>
       )}
           <div ref={conversationEndRef} />
         </div>
         </div>
       <div style={{ position: 'absolute', top: '20px', right: '20px', zIndex: 10 }}>
         <button onClick={() => navigate('/study')} style={{ padding: '12px 24px', background: 'rgba(255, 255, 255, 0.2)', color: 'white', border: '1px solid rgba(255, 255, 255, 0.3)', borderRadius: '16px', cursor: 'pointer', fontSize: '14px', fontWeight: '600' }}>å‹‰å¼·ã«æˆ»ã‚‹</button>
         </div>
       <div style={{ position: 'absolute', top: '20px', left: '20px', zIndex: 10, background: 'rgba(255, 255, 255, 0.9)', borderRadius: '12px', padding: '8px 12px', display: 'flex', alignItems: 'center', gap: '8px', boxShadow: '0 4px 16px rgba(0, 0, 0, 0.1)' }}>
         <div style={{ width: '10px', height: '10px', borderRadius: '50%', background: isAiConnected ? '#10b981' : isConnecting ? '#f59e0b' : '#ef4444', animation: isConnecting ? 'pulse 1.5s infinite' : 'none' }} />
         <span style={{ fontSize: '14px', fontWeight: '600', color: '#333' }}>{isAiConnected ? 'AIæ¥ç¶šä¸­' : isConnecting ? 'æ¥ç¶šä¸­...' : 'AIæœªæ¥ç¶š'}</span>
       </div>
       {!isAiConnected && !isConnecting && (
         <div style={{ position: 'absolute', bottom: '20px', left: '50%', transform: 'translateX(-50%)', zIndex: 10 }}>
           <button onClick={startConnection} style={{ padding: '12px 24px', background: 'rgba(16, 185, 129, 0.8)', color: 'white', border: 'none', borderRadius: '16px', cursor: 'pointer', fontSize: '14px', fontWeight: '600' }}>AIã¨è©±ã™</button>
         </div>
       )}
     </div>
   </div>
 )
}
